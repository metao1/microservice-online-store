server:
  error:
    include-message: always
    include-binding-errors: always
  port: ${PORT:8083}

spring:
  application:
    name: product-microservice
  kafka:
    # Required connection configs for Kafka producer, consumer, and admin
    bootstrap-servers: ${BOOTSTRAP_SERVERS}
    # Required connection configs for Confluent Cloud Schema Registry
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL}
      security.protocol: ${SECURITY_PROTOCOL}
      sasl.mechanism: ${SASL_MECHANISM}
      sasl.jaas.config: ${SASL_JAAS_CONFIG}
    consumer:
      key-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      isolation-level: read_committed
      auto-offset-reset: none
      enable-auto-commit: false
      properties:
        session.timeout.ms: 30000
        max.poll.interval.ms: 300
        max.idle.time.ms: 60000
        heartbeat.interval.ms: 1000
        auto.offset.reset: latest
        allow.auto.create.topics: 'false'
        spring.deserializer.key.delegate.class: org.apache.kafka.common.serialization.StringDeserializer
        spring.deserializer.value.delegate.class: io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
      properties:
        enable.idempotence: true
  output.ansi.enabled: ALWAYS
  datasource:
    url: ${DATABASE_URL}
    username: ${DATABASE_USER}
    password: ${DATABASE_PASSWORD}
    hikari:
      auto-commit: false
      schema: "bookstore"
  flyway:
    enabled: true
    baseline-version: 0
    outOfOrder: false
    locations: classpath:migration
    clean-disabled: false
    create-schemas: true
    baseline-on-migrate: true
    validate-on-migrate: true
  jpa:
    database: POSTGRESQL
    generate-ddl: false
    properties:
      open-in-view: false
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        jdbc:
          batch_size: 20
          order_inserts: true
          order_updates: true
          batch_versioned_data: true
        cache:
          use_query_cache: true
          use_second_level_cache: true
          region.factory_class: org.hibernate.cache.jcache.JCacheRegionFactory
          jcache:
            provider: com.github.benmanes.caffeine.jcache.spi.CaffeineCachingProvider
            configuration_resource_name: ehcache.xml
        connection:
          provider_disables_autocommit: true
        temp:
          use_jdbc_metadata_defaults: false

product-sample-data-path: data/products.txt

kafka:
  enabled: ${KAFKA_ENABLED:true}
  topic:
    product-created:
      id: "product-created-id"
      name: "product-created"
      group-id: "product-created-group"
      class-path: "com.metao.book.product.ProductCreatedEvent"
    product-updated:
      id: "product-updated-id"
      name: "product-updated"
      group-id: "product-updated-group"
      class-path: "com.metao.book.shared.ProductUpdatedEvent"

logging:
  pattern.console: "%clr(%d{HH:mm:ss.SSS}){blue} %clr(---){faint} %clr([%t]){yellow} %clr(:){red} %clr(%m){faint}%n"
  level:
    org.springframework.data: INFO
    org.springframework.boot.autoconfigure: ERROR
    org.hibernate: INFO